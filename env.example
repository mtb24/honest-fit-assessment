# Copy to .env.local and set provider config (never commit secrets)
# Providers: mock | openai | cursor | ollama
LLM_PROVIDER=mock
LLM_FALLBACK_PROVIDERS=
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.2

# OpenAI-compatible settings
OPENAI_API_KEY=your_openai_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# Cursor provider settings (only needed when LLM_PROVIDER=cursor)
CURSOR_API_KEY=your_cursor_key_here
CURSOR_BASE_URL=https://api.cursor.com

# Ollama provider settings (only needed when LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.2
